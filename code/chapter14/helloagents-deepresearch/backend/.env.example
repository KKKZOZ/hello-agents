# Which search service to use, either 'duckduckgo', 'tavily', 'perplexity', Searxng
SEARCH_API='duckduckgo'

# LLM配置 (从HelloAgents继承,如需覆盖可在此配置)

# 模型提供者
LLM_PROVIDER=custom          # Options: ollama, lmstudio, custom 其中ollama和lmstudio都是用于本地大模型配置，custom是用于自定义大模型配置[用于api调用]
# 模型名称
LLM_MODEL_ID=your-model-name

# API密钥
LLM_API_KEY=your-api-key-here

# 服务地址
LLM_BASE_URL=your-api-base-url

# 超时时间（可选，默认60秒）
LLM_TIMEOUT=60

# 服务器配置
HOST=0.0.0.0
PORT=8000

# CORS配置
CORS_ORIGINS=http://localhost:5173,http://localhost:3000

# 日志级别
LOG_LEVEL=INFO
# Web Search API Keys (choose one or both)
# TAVILY_API_KEY=tvly-xxxxx      # Get your key at https://tavily.com
# PERPLEXITY_API_KEY=pplx-xxxxx  # Get your key at https://www.perplexity.ai
# For Searxng search, defaults to http://localhost:8888
# SEARXNG_URL=

# 本地模型配置(LMStudio/Ollama)
# LLM_PROVIDER=lmstudio          # Options: ollama, lmstudio
# LOCAL_LLM=qwen_qwq-32b         # Model name in LMStudio/Ollama
# LMSTUDIO_BASE_URL=http://localhost:1234/v1  # LMStudio OpenAI-compatible API URL
# OLLAMA_BASE_URL=http://localhost:11434 # the endpoint of the Ollama service, defaults to http://localhost:11434 if not set

MAX_WEB_RESEARCH_LOOPS=3
FETCH_FULL_PAGE=True